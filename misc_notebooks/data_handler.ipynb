{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "787367b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "#import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "#import data_cleaning as dc\n",
    "#import pandas as pd\n",
    "import calendar as cal \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a662bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(arr,true_arr):\n",
    "    ## Given 1d-array and its theoretical/true value calculated rmse.\n",
    "    rmse = np.zeros(arr.size)\n",
    "    rmse = np.sqrt(np.mean(np.square(arr-true_arr)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0faf9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_moment_adjust(otemp,omean,std_ratio, mmd, dtratio, mean_dtratio):\n",
    "    ##### Sratio-scaling #############\n",
    "    adjusted_mean = omean - mean_dtratio*mmd\n",
    "    numerator    = otemp - dtratio*(mmd+(1-std_ratio)*adjusted_mean)\n",
    "    denominator  = 1 - dtratio*(1-std_ratio)\n",
    "    #print('madj,num,denom=',adjusted_mean,numerator,denominator)\n",
    "    ###### No Sratio -Scaling #################\n",
    "    # numerator = otemp - dtratio*mmd\n",
    "    # denominator = 1\n",
    "    return numerator,denominator,numerator/denominator\n",
    "\n",
    "# def two_moment_adjust(observed_temp, observed_mean, std_ratio, mean_displacement, delta_temp_ratio, mean_delta_temp_ratio):\n",
    "#     adjusted_mean = observed_mean - mean_delta_temp_ratio*mean_displacement\n",
    "#     numerator = observed_temp - delta_temp_ratio*((1-std_ratio)*adjusted_mean+mean_displacement)\n",
    "#     denominator = 1 - delta_temp_ratio*(1-std_ratio)\n",
    "#     return numerator/denominator\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    \"\"\"Finds index holding number closest to value\"\"\"\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx\n",
    "\n",
    "\n",
    "########################################\n",
    "def get_jan_1st_indices_obs(start_year,end_year):\n",
    "    \"\"\"Given start_year and end_year, returns indices of every January 1st\"\"\"\n",
    "    jan_1st_index = np.zeros(end_year-start_year+1,dtype=int)\n",
    "    days =0\n",
    "    for year in range(start_year,end_year+1):\n",
    "        jan_1st_index[year-start_year] = days\n",
    "        if(cal.isleap(year)):\n",
    "           days_in_year = 366\n",
    "        else:\n",
    "           days_in_year = 365   \n",
    "        days+=days_in_year\n",
    "    return jan_1st_index\n",
    "\n",
    "def get_yearday_indcs(start_year,end_year,year_day):\n",
    "    \"Gets the indices corr to a year day. Drops Feb 29 indices\"\n",
    "    indcs      = np.zeros(end_year-start_year+1,dtype=int)\n",
    "    jan1_indcs = np.zeros(end_year-start_year+1,dtype=int) \n",
    "    jan1_indcs = get_jan_1st_indices_obs(start_year,end_year)\n",
    "   \n",
    "    for year in range(start_year,end_year+1):\n",
    "        time       = year -start_year\n",
    "        if (cal.isleap(year)==False):\n",
    "            indcs[time] = jan1_indcs[time] + year_day \n",
    "        else:       \n",
    "            if (year_day<59): \n",
    "               #print('-year-')\n",
    "               #print(year)\n",
    "               indcs[time]  =  jan1_indcs[time] + year_day \n",
    "            else:\n",
    "               indcs[time]  =  jan1_indcs[time] +year_day +1\n",
    "    return indcs\n",
    "\n",
    "def get_feb29_indices(start_year,end_year):\n",
    "    \"\"\"Get the feb 29 indices of a dataset.\"\"\"\n",
    "    feb29_indx = np.zeros(end_year-start_year+1,dtype=int)\n",
    "    jan1_indx  = get_jan_1st_indices_obs(start_year, end_year)\n",
    "    for year in range(start_year,end_year+1):\n",
    "        if(cal.isleap(year)):\n",
    "           feb29_indx[year-start_year] = jan1_indx[year-start_year] + 59\n",
    "        else:\n",
    "            feb29_indx[year-start_year]     = 0\n",
    "    return feb29_indx[feb29_indx != 0]\n",
    "\n",
    "def calc_annual_mean(data,start_year,end_year):\n",
    "    \"\"\"Given 1d data with index by days (0 to last_day), calculates the annual mean\n",
    "    for each year from start_year to end_year. Handles leap years.\"\"\"\n",
    "    jan1_indx  =  get_jan_1st_indices_obs(start_year, end_year)\n",
    "    dec31_indx =  get_yearday_indcs(start_year,end_year,365) \n",
    "    amean      =  np.zeros(end_year-start_year+1)\n",
    "    for year in range(start_year,end_year+1):\n",
    "        amean[year-start_year] = data[jan1_indx[year-start_year]:dec31_indx[year-start_year]].mean()\n",
    "    return amean\n",
    "    \n",
    "def calc_monthly_mean(data,start_year,end_year):\n",
    "    \"\"\"Given monthly data, calculates the monthly mean (over years)\n",
    "    for each year from start_year to end_year. Handles leap years.\"\"\"\n",
    "    jan1_indx  =  get_jan_1st_indices_obs(start_year, end_year)\n",
    "    dec31_indx =  get_yearday_indcs(start_year,end_year,365) \n",
    "    amean      =  np.zeros(end_year-start_year+1)\n",
    "    for year in range(start_year,end_year+1):\n",
    "        amean[year-start_year] = data[jan1_indx[year-start_year]:dec31_indx[year-start_year]].mean()\n",
    "    return amean\n",
    "\n",
    "def get_model_means():\n",
    "    \"\"\"Reads and fetches netcdf files with the model means\"\"\"\n",
    "    pim = nc.Dataset(pim_path)\n",
    "    #print(pim)\n",
    "    smooth_pim = np.zeros((365,19,42))\n",
    "    smooth_pim = pim.variables['smoothed_pimeans'][:,:,:]\n",
    "    pim.close()\n",
    "\n",
    "    icm  = nc.Dataset(icm_path)\n",
    "    #print(icm)\n",
    "    smooth_icm = np.zeros((365,19,42))\n",
    "    smooth_icm = icm.variables['smoothed_icmeans'][:,:,:]\n",
    "    icm.close()\n",
    "    return {\"ic\": smooth_icm, \"pi\": smooth_pim}\n",
    "\n",
    "def get_conus_latlon():\n",
    "    pim2 = nc.Dataset(pim_path)\n",
    "    #print(pim)\n",
    "    lats = np.zeros(19)\n",
    "    lons = np.zeros(42)\n",
    "    lats = pim2.variables['lats'][:]\n",
    "    lons = pim2.variables['lons'][:]\n",
    "    pim2.close()\n",
    "    return {\"lats\":lats,\"lons\":lons} \n",
    "\n",
    "\n",
    "def get_model_stds():\n",
    "    \"\"\"Reads and fetches netcdf files with the model means\"\"\"\n",
    "    pis  = nc.Dataset(pis_path)\n",
    "    #print(pis)\n",
    "    smooth_pis = np.zeros((365,19,42))\n",
    "    smooth_pis = pis.variables['smoothed_pistdevs'][:,:,:]\n",
    "    pis.close()\n",
    "\n",
    "    ics = nc.Dataset(ics_path)\n",
    "    smooth_ics = np.zeros((365,19,42))\n",
    "    smooth_ics = ics.variables['smoothed_icstdevs'][:,:,:]\n",
    "    ics.close()\n",
    "\n",
    "    return {\"ic\": smooth_ics, \"pi\": smooth_pis}\n",
    "\n",
    "def get_tdratio(anomaly_name):\n",
    "    ga = nc.Dataset(gta_path)\n",
    "    na  = ga.variables[anomaly_name][:]\n",
    "    ga.close()\n",
    "    \n",
    "    return na/(tot_icmean-tot_pimean)\n",
    "    \n",
    "def calc_ann_global_mean(data,spinup,nyears,var='tas'):\n",
    "    \"\"\" Given monthly data, calculates, annual global mean\"\"\"\n",
    "    lat_bnds = data['lat_bnds']\n",
    "    lower_bounds = np.deg2rad(lat_bnds[:,0])\n",
    "    upper_bounds = np.deg2rad(lat_bnds[:,1])\n",
    "    lats         = np.deg2rad(data['lat'])\n",
    "    weights = (np.cos(lats)*(upper_bounds-lower_bounds))\n",
    "    print(np.sum(weights))\n",
    "    weights = weights/np.sum(weights)\n",
    "    print('weights=',np.sum(weights))\n",
    "    temp = np.zeros(nyears*12)\n",
    "    atemp = np.zeros(nyears)\n",
    "    start = spinup*12\n",
    "    stop = (spinup+nyears)*12\n",
    "    \n",
    "    for i in range(start, stop):\n",
    "        tas = data[var][i,:,:]\n",
    "        spatial_mean = np.average(tas, axis=0, weights=weights).mean()\n",
    "        temp[i-start] = spatial_mean\n",
    "    for j in range(nyears):\n",
    "        atemp[j] = np.mean(temp[12*j:12*(j+1)])\n",
    "    return atemp\n",
    "\n",
    "    \n",
    "def calc_global_mean(data,start_year,end_year,var='tasmax'):\n",
    "    \"\"\" Given data, calculates, annual global mean\"\"\"\n",
    "    lat_bnds = data['lat_bnds']\n",
    "    lower_bounds = np.deg2rad(lat_bnds[:,0])\n",
    "    upper_bounds = np.deg2rad(lat_bnds[:,1])\n",
    "    lats         = np.deg2rad(data['lat'])\n",
    "    weights = (np.cos(lats)*(upper_bounds-lower_bounds))\n",
    "    print(np.sum(weights))\n",
    "    weights = weights/np.sum(weights)\n",
    "    print('sum of weights=',np.sum(weights))\n",
    "    #atemp      = np.zeros(end_year-start_year+1)\n",
    "    jan1_indx  =  get_jan_1st_indices_obs(start_year, end_year)\n",
    "    dec31_indx =  get_yearday_indcs(start_year,end_year,365) \n",
    "    start      = jan1_indx[0]\n",
    "    stop       = dec31_indx[-1]\n",
    "    temp       = np.zeros(stop-start)\n",
    "    \n",
    "    for i in range(start,stop):\n",
    "        tasmax2d = data[var][i,:,:]\n",
    "        spatial_mean = np.average(tasmax2d, axis=0, weights=weights).mean()\n",
    "        temp[i-start] = spatial_mean\n",
    "    print(spatial_mean)   \n",
    "     \n",
    "    atemp = calc_annual_mean(temp,start_year,end_year)\n",
    "    return atemp\n",
    "\n",
    "def calc_regional_amean(data,start_year,end_year,lat0,lat1,lon0,lon1):\n",
    "    \"\"\" Given data, calculates, annual regional mean, need to specify lat and lon bounds.\"\"\"\n",
    "    lat_bnds = data['lat_bnds']\n",
    "    lats         = data['lat']\n",
    "    lons         = data['lon']\n",
    "    print(lats)\n",
    "    #### Crop lats and lat_bnds to only include region of interest (lat0,lat1)\n",
    "    lt0     = find_nearest(lats,lat0)\n",
    "    lt1     = find_nearest(lats,lat1)\n",
    "    ln0     = find_nearest(lons,lon0)\n",
    "    ln1     = find_nearest(lons,lon1)\n",
    "    print(lt0,lt1,ln0,ln1)\n",
    "    print('Computing regional annual mean for the following box:')\n",
    "    print('lats=',lats[lt0],lats[lt1],'lons=',lons[ln0],lons[ln1])\n",
    "    lower_bounds = np.deg2rad(lat_bnds[lt0:lt1,0])\n",
    "    upper_bounds = np.deg2rad(lat_bnds[lt0:lt1,1])\n",
    "    lats         = np.deg2rad(lats[lt0:lt1])    \n",
    "    ###########################\n",
    "    weights = (np.cos(lats)*(upper_bounds-lower_bounds))\n",
    "    print(np.sum(weights))\n",
    "    weights = weights/np.sum(weights)\n",
    "    print('sum of weights=',np.sum(weights))\n",
    "    #atemp      = np.zeros(end_year-start_year+1)\n",
    "    jan1_indx  =  get_jan_1st_indices_obs(start_year, end_year)\n",
    "    dec31_indx =  get_yearday_indcs(start_year,end_year,365) \n",
    "    start      = jan1_indx[0]\n",
    "    stop       = dec31_indx[-1]\n",
    "    temp       = np.zeros(stop-start)\n",
    "    \n",
    "    for i in range(start,stop):\n",
    "        tasmax2d = data['tasmax'][i,lt0:lt1,ln0:ln1]\n",
    "        spatial_mean = np.average(tasmax2d, axis=0, weights=weights).mean()\n",
    "        temp[i-start] = spatial_mean\n",
    "    print(spatial_mean)   \n",
    "     \n",
    "    atemp = calc_annual_mean(temp,start_year,end_year)\n",
    "    return atemp\n",
    "\n",
    "\n",
    "def get_colors_list(vmin0,vmax0,thresh0,thresh1,binsize):\n",
    "    \"\"\"Given range of data [vmin,vmax] and threshold [thresh0,thresh1], returns an array\n",
    "    which can be used to get colorbar with threshold region white. \n",
    "    Also, returns binsize for colorbar\"\"\"\n",
    "    vscale = vmax0-vmin0\n",
    "    x0 = ((thresh0 -vmin0)/vscale) \n",
    "    x1 = ((thresh1-vmin0)/vscale)\n",
    "    #We want to map intervals [vmin,threshold0], [threshold0,threshold1] and [threshold1,vmax] \n",
    "    #to the intervals [0,x0],[x0,x1] and [x1,1]. We will do this by creating an array with size \n",
    "    #ratios n0:100-n0-n1:n1.    \n",
    "    n0 =   int(x0*100)  \n",
    "    n1 = int((1-x1)*100)\n",
    "    y = 0.5\n",
    "    lower = plt.cm.seismic(np.linspace(0,y, n0))\n",
    "    white = plt.cm.seismic(np.ones(100-n0-n1)*0.5)\n",
    "    upper = plt.cm.seismic(np.linspace(1-y, 1, n1))\n",
    "    colors_list = np.vstack((lower, white, upper))\n",
    "    bins = np.arange(vmin0,vmax0+binsize,binsize)\n",
    "    print('bins=',bins)\n",
    "    return colors_list,bins\n",
    "\n",
    "def get_colors_list0(vmin0,vmax0,thresh0,thresh1,binsize):\n",
    "    \"\"\"Given range of data [vmin,vmax] and threshold [thresh0,thresh1], returns an array\n",
    "    which can be used to get colorbar with threshold region white. \n",
    "    Also, returns binsize for colorbar\"\"\"\n",
    "    vscale = vmax0-vmin0\n",
    "    x0 = ((thresh0 -vmin0)/vscale) \n",
    "    x1 = ((thresh1-vmin0)/vscale)\n",
    "    #We want to map intervals [vmin,threshold0], [threshold0,threshold1] and [threshold1,vmax] \n",
    "    #to the intervals [0,x0],[x0,x1] and [x1,1]. We will do this by creating an array with size \n",
    "    #ratios n0:100-n0-n1:n1.    \n",
    "    n0 =   int(x0*100)  \n",
    "    n1 = int((1-x1)*100)\n",
    "    y = 0.5\n",
    "    lower = plt.cm.seismic(np.linspace(0,y, n0))\n",
    "    white = plt.cm.seismic(np.ones(100-n0-n1)*0.5)\n",
    "    upper = plt.cm.seismic(np.linspace(1-y, 1, n1))\n",
    "    colors_list = np.vstack((lower, white, upper))\n",
    "    bins = np.arange(vmin0,vmax0+binsize,binsize)\n",
    "    print('bins=',bins)\n",
    "    return colors_list,bins\n",
    "    \n",
    "def cmap_map(function, cmap):\n",
    "    \"\"\" Applies function (which should operate on vectors of shape 3: [r, g, b]), on colormap cmap.\n",
    "    This routine will break any discontinuous points in a colormap.\n",
    "    \"\"\"\n",
    "    cdict = cmap._segmentdata\n",
    "    step_dict = {}\n",
    "    # Firt get the list of points where the segments start or end\n",
    "    for key in ('red', 'green', 'blue'):\n",
    "        step_dict[key] = list(map(lambda x: x[0], cdict[key]))\n",
    "    step_list = sum(step_dict.values(), [])\n",
    "    step_list = np.array(list(set(step_list)))\n",
    "    # Then compute the LUT, and apply the function to the LUT\n",
    "    reduced_cmap = lambda step : np.array(cmap(step)[0:3])\n",
    "    old_LUT = np.array(list(map(reduced_cmap, step_list)))\n",
    "    new_LUT = np.array(list(map(function, old_LUT)))\n",
    "    # Now try to make a minimal segment definition of the new LUT\n",
    "    cdict = {}\n",
    "    for i, key in enumerate(['red','green','blue']):\n",
    "        this_cdict = {}\n",
    "        for j, step in enumerate(step_list):\n",
    "            if step in step_dict[key]:\n",
    "                this_cdict[step] = new_LUT[j, i]\n",
    "            elif new_LUT[j,i] != old_LUT[j, i]:\n",
    "                this_cdict[step] = new_LUT[j, i]\n",
    "        colorvector = list(map(lambda x: x + (x[1], ), this_cdict.items()))\n",
    "        colorvector.sort()\n",
    "        cdict[key] = colorvector\n",
    "    return plt.colors.LinearSegmentedColormap('colormap',cdict,1024)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97552b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
